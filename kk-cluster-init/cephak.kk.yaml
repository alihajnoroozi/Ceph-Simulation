apiVersion: kubekey.kubesphere.io/v1alpha2
kind: Cluster
metadata:
  name: sample
spec:
  hosts:
  - {name: cephak01, address: 192.168.64.101 , internalAddress: 192.168.64.101 , user: nakai, port: 22, privateKeyPath: "/home/ali/.ssh/kk_user" }
  - {name: cephak02, address: 192.168.64.102 , internalAddress: 192.168.64.102 , user: nakai, port: 22, privateKeyPath: "/home/ali/.ssh/kk_user" }
  - {name: cephak03, address: 192.168.64.103 , internalAddress: 192.168.64.103 , user: nakai, port: 22, privateKeyPath: "/home/ali/.ssh/kk_user" }
  - {name: cephak04, address: 192.168.64.104 , internalAddress: 192.168.64.104 , user: nakai, port: 22, privateKeyPath: "/home/ali/.ssh/kk_user" }
  roleGroups:
    etcd:
    - cephak01 
    - cephak02 
    - cephak03 
    master:
    - cephak01 
    - cephak02 
    - cephak03 
    worker:
    - cephak01
    - cephak02
    - cephak03
    - cephak04
  controlPlaneEndpoint:
    internalLoadbalancer: kube-vip 
    domain: lb.cephak.sheida.co
    address: 192.168.64.10
    port: 6443
    vip: "192.168.64.100"

  system:
    # ntpServers: #  The ntp servers of chrony.
    #   - time1.cloud.tencent.com
    #   - ntp.aliyun.com
    #   - node1 # Set the node name in `hosts` as ntp server if no public ntp servers access.
    # timezone: "Asia/Shanghai"
    # rpms: # Specify additional packages to be installed. The ISO file which is contained in the artifact is required.
    #   - nfs-utils
    debs:
      - nfs-common
      - bmon
      - net-tools
      - socat
      - curl 
      - ipset
      - ipvsadm 

    #preInstall:  # Specify custom init shell scripts for each nodes, and execute according to the list order.
    #  - name: format and mount disk  
    #    bash: /bin/bash -x setup-disk.sh
    #    materials: # scripts can has some dependency materials. those will copy to the node        
    #      - ./setup-disk.sh # the script which shell execute need
    #      -  xxx            # other tools materials need by this script
    #postInstall: # Specify custom finish clean up shell scripts for each nodes after the kubernetes install.
    #  - name: clean tmps files
    #    bash: |
    #       rm -fr /tmp/kubekey/*
    #skipConfigureOS: true # Do not pre-configure the host OS (e.g. kernel modules, /etc/hosts, sysctl.conf, NTP servers, etc). You will have to set these things up via other methods before using KubeKey.

  kubernetes:
    version: v1.28.0
    # imageRepo: kubesphere
    containerManager: crio # Container Runtime, support: containerd, cri-o, isula. [Default: docker]
    clusterName: cephak.sheida.co
    autoRenewCerts: true # Whether to install a script which can automatically renew the Kubernetes control plane certificates. [Default: false]
    # masqueradeAll: false  # masqueradeAll tells kube-proxy to SNAT everything if using the pure iptables proxy mode. [Default: false].
    maxPods: 110  # maxPods is the number of Pods that can run on this Kubelet. [Default: 110]
    podPidsLimit: 10000 # podPidsLimit is the maximum number of PIDs in any pod. [Default: 10000]
    # nodeCidrMaskSize: 24  # The internal network node size allocation. This is the size allocated to each node on your network. [Default: 24]
    proxyMode: ipvs  # Specify which proxy mode to use. [Default: ipvs]
    # featureGates: # enable featureGates, [Default: {"ExpandCSIVolumes":true,"RotateKubeletServerCertificate": true,"CSIStorageCapacity":true, "TTLAfterFinished":true}]
    #   CSIStorageCapacity: true
    #   ExpandCSIVolumes: true
    #   RotateKubeletServerCertificate: true
    #   TTLAfterFinished: true
    ## support kata and NFD
    # kata:
    #   enabled: true
    # nodeFeatureDiscovery
    #   enabled: true
    # additional kube-proxy configurations
    # kubeProxyConfiguration:
    #   ipvs:
    #     # CIDR's to exclude when cleaning up IPVS rules.
    #     # necessary to put node cidr here when internalLoadbalancer=kube-vip and proxyMode=ipvs
    #     # refer to: https://github.com/kubesphere/kubekey/issues/1702
    #     excludeCIDRs:
    #       - 172.16.0.2/24192.168.10.20
  # etcd:
    # type: kubekey  # Specify the type of etcd used by the cluster. When the cluster type is k3s, setting this parameter to kubeadm is invalid. [kubekey | kubeadm | external] [Default: kubekey]
    ## The following parameters need to be added only when the type is set to external.
    ## caFile, certFile and keyFile need not be set, if TLS authentication is not enabled for the existing etcd.
    # external:
    #   endpoints:
    #     - https://192.168.6.6:2379
    #   caFile: /pki/etcd/ca.crt
    #   certFile: /pki/etcd/etcd.crt
    #   keyFile: /pki/etcd/etcd.key
  network:
    # plugin: culium
    plugin: calico
    calico:
      ipipMode: Always  # IPIP Mode to use for the IPv4 POOL created at start up. If set to a value other than Never, vxlanMode should be set to "Never". [Always | CrossSubnet | Never] [Default: Always]
      vxlanMode: Never  # VXLAN Mode to use for the IPv4 POOL created at start up. If set to a value other than Never, ipipMode should be set to "Never". [Always | CrossSubnet | Never] [Default: Never]
      vethMTU: 0  # The maximum transmission unit (MTU) setting determines the largest packet size that can be transmitted through your network. By default, MTU is auto-detected. [Default: 0]
    kubePodsCIDR: 10.235.0.0/16
    kubeServiceCIDR: 10.236.0.0/16
    multusCNI:
      enabled: true
  # storage:
  #   openebs:
  #     basePath: /storage # base path of the local PV provisioner
  # registry:
  #   privateRegistry: "repo.simra.cloud/dockerhub"
  #   registryMirrors: []
  #   insecureRegistries: []
    # namespaceOverride: ""
    # auths: # if docker add by `docker login`, if containerd append to `/etc/containerd/config.toml`
    #   "dockerhub.kubekey.local":
    #     username: "xxx"
    #     password: "***"
    #     skipTLSVerify: false # Allow contacting registries over HTTPS with failed TLS verification.
    #     plainHTTP: false # Allow contacting registries over HTTP.
    #     certsPath: "/etc/docker/certs.d/dockerhub.kubekey.local" # Use certificates at path (*.crt, *.cert, *.key) to connect to the registry.
  # addons: [] # You can install cloud-native addons (Chart or YAML) by using this field.

# ---
# apiVersion: installer.kubesphere.io/v1alpha1
# kind: ClusterConfiguration
# metadata:
#   name: ks-installer
#   namespace: kubesphere-system
#   labels:
#     version: v3.1.0
# spec:
#   persistence:
#     storageClass: ""        # If there is no default StorageClass in your cluster, you need to specify an existing StorageClass here.
#   authentication:
#     jwtSecret: ""           # Keep the jwtSecret consistent with the Host Cluster. Retrieve the jwtSecret by executing "kubectl -n kubesphere-system get cm kubesphere-config -o yaml | grep -v "apiVersion" | grep jwtSecret" on the Host Cluster.
#   local_registry: ""        # Add your private registry address if it is needed.
#   etcd:
#     monitoring: false       # Enable or disable etcd monitoring dashboard installation. You have to create a Secret for etcd before you enable it.
#     endpointIps: localhost  # etcd cluster EndpointIps. It can be a bunch of IPs here.
#     port: 2379              # etcd port.
#     tlsEnable: true
#   common:
#     redis:
#       enabled: false
#     openldap:
#       enabled: false
#     minioVolumeSize: 20Gi # Minio PVC size.
#     openldapVolumeSize: 2Gi   # openldap PVC size.
#     redisVolumSize: 2Gi # Redis PVC size.
#     monitoring:
#       endpoint: http://prometheus-operated.kubesphere-monitoring-system.svc:9090 # Prometheus endpoint to get metrics data.
#     es:   # Storage backend for logging, events and auditing.
#       # elasticsearchMasterReplicas: 1   # The total number of master nodes. Even numbers are not allowed.
#       # elasticsearchDataReplicas: 1     # The total number of data nodes.
#       elasticsearchMasterVolumeSize: 4Gi   # The volume size of Elasticsearch master nodes.
#       elasticsearchDataVolumeSize: 20Gi    # The volume size of Elasticsearch data nodes.
#       logMaxAge: 7                     # Log retention time in built-in Elasticsearch. It is 7 days by default.
#       elkPrefix: logstash              # The string making up index names. The index name will be formatted as ks-<elk_prefix>-log.
#       basicAuth:rsistence:
#     storageClass: ""        # If there is no default StorageClass in your cluster, you need to specify an existing StorageClass here.
#   authentication:
#     jwtSecret: ""           # Keep the jwtSecret consistent with the Host Cluster. Retrieve the jwtSecret by executing "kubectl -n kubesphere-system get cm kubesphere-config -o yaml | grep -v "apiVersion" | grep jwtSecret" on the Host Cluster.
#   local_registry: ""        # Add your private registry address if it is needed.
#   etcd:
#     monitoring: false    e, Memory: 100 MiB) It enables users to customize alerting policies to send messages to receivers in time with different time intervals and alerting levels to choose from.
#     enabled: false         # Enable or disable the KubeSphere Alerting System.
#     # thanosruler:
#     #   replicas: 1
#     #   resources: {}
#   auditing:                # Provide a security-relevant chronological set of recordsï¼Œrecording the sequence of activities happening on the platform, initiated by different tenants.
#     enabled: false         # Enable or disable the KubeSphere Auditing Log System. 
#   devops:                  # (CPU: 0.47 Core, Memory: 8.6 G) Provide an out-of-the-box CI/CD system based on Jenkins, and automated workflow tools including Source-to-Image & Binary-to-Image.
#     enabled: false             # Enable or disable the KubeSphere DevOps System.
#     jenkinsMemoryLim: 2Gi      # Jenkins memory limit.
#     jenkinsMemoryReq: 1500Mi   # Jenkins memory request.
#     jenkinsVolumeSize: 8Gi     # Jenkins volume size.
#     jenkinsJavaOpts_Xms: 512m  # The following three fields are JVM parameters.
#     jenkinsJavaOpts_Xmx: 512m
#     jenkinsJavaOpts_MaxRAM: 2g
#   events:                  # Provide a graphical web console for Kubernetes Events exporting, filtering and alerting in multi-tenant Kubernetes clusters.
#     enabled: false         # Enable or disable the KubeSphere Events System.
#     ruler:
#       enabled: true
#       replicas: 2
#   logging:                 # (CPU: 57 m, Memory: 2.76 G) Flexible logging functions are provided for log query, collection and management in a unified console. Additional log collectors can be added, such as Elasticsearch, Kafka and Fluentd.
#     enabled: false         # Enable or disable the KubeSphere Logging System.
#     logsidecar:
#       enabled: true
#       replicas: 2
#   metrics_server:                    # (CPU: 56 m, Memory: 44.35 MiB) It enables HPA (Horizontal Pod Autoscaler).
#     enabled: false                   # Enable or disable metrics-server.
#   monitoring:
#     storageClass: ""                 # If there is an independent StorageClass you need for Prometheus, you can specify it here. The default StorageClass is used by default.
#     # prometheusReplicas: 1          # Prometheus replicas are responsible for monitoring different segments of data source and providing high availability.
#     prometheusMemoryRequest: 400Mi   # Prometheus request memory.
#     prometheusVolumeSize: 20Gi       # Prometheus PVC size.
#     # alertmanagerReplicas: 1          # AlertManager Replicas.
#   multicluster:
#     clusterRole: none  # host | member | none  # You can install a solo cluster, or specify it as the Host or Member Cluster.
#   network:
#     networkpolicy: # Network policies allow network isolation within the same cluster, which means firewalls can be set up between certain instances (Pods).
#       # Make sure that the CNI network plugin used by the cluster supports NetworkPolicy. There are a number of CNI network plugins that support NetworkPolicy, including Calico, Cilium, Kube-router, Romana and Weave Net.
#       enabled: false # Enable or disable network policies.
#     ippool: # Use Pod IP Pools to manage the Pod network address space. Pods to be created can be assigned IP addresses from a Pod IP Pool.
#       type: none # Specify "calico" for this field if Calico is used as your CNI plugin. "none" means that Pod IP Pools are disabled.
#     topology: # Use Service Topology to view Service-to-Service communication based on Weave Scope.
#       type: none # Specify "weave-scope" for this field to enable Service Topology. "none" means that Service Topology is disabled.
#   openpitrix: # An App Store that is accessible to all platform tenants. You can use it to manage apps across their entire lifecycle.
#     store:
#       enabled: false # Enable or disable the KubeSphere App Store.
#   servicemesh:         # (0.3 Core, 300 MiB) Provide fine-grained traffic management, observability and tracing, and visualized traffic topology.
#     enabled: false     # Base component (pilot). Enable or disable KubeSphere Service Mesh (Istio-based).
#   kubeedge:          # Add edge nodes to your cluster and deploy workloads on edge nodes.
#     enabled: false   # Enable or disable KubeEdge.
#     cloudCore:
#       nodeSelector: {"node-role.kubernetes.io/worker": ""}
#       tolerations: []
#       cloudhubPort: "10000"
#       cloudhubQuicPort: "10001"
#       cloudhubHttpsPort: "10002"
#       cloudstreamPort: "10003"
#       tunnelPort: "10004"
#       cloudHub:
#         advertiseAddress: # At least a public IP address or an IP address which can be accessed by edge nodes must be provided.
#           - ""            # Note that once KubeEdge is enabled, CloudCore will malfunction if the address is not provided.
#         nodeLimit: "100"
#       service:
#         cloudhubNodePort: "30000"
#         cloudhubQuicNodePort: "30001"
#         cloudhubHttpsNodePort: "30002"
#         cloudstreamNodePort: "30003"
#         tunnelNodePort: "30004"
#     edgeWatcher:
#       nodeSelector: {"node-role.kubernetes.io/worker": ""}
#       tolerations: []
#       edgeWatcherAgent:
#         nodeSelector: {"node-role.kubernetes.io/worker": ""}
#         tolerations: []192.168.10.16